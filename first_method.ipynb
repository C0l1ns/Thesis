{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import (\n",
    "    collect_cluster_center_target_coordinates,\n",
    "    insert_column,\n",
    "    display_errors,\n",
    "    flat_errors\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(x1, x2, reversed=False):\n",
    "    x1_size, x2_size = len(x1), len(x2)\n",
    "    features = np.array([np.concatenate((x2[j][:-1], x1[i][:-1])) if reversed else np.concatenate((x1[i][:-1], x2[j][:-1])) \n",
    "                         for i in range(x1_size) for j in range(x2_size)])   \n",
    "    labels = np.array([(x2[j][-1] - x1[i][-1]) if reversed else (x1[i][-1] - x2[j][-1]) \n",
    "                       for i in range(x1_size) for j in range(x2_size)])\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_yn(z, y_sum, N):\n",
    "    return np.array([(y_sum + sum(z[i: i + N])) / N for i in range(0, len(z), N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_path = \"./datasets/body_fat_train.txt\"\n",
    "test_dataset_path = \"./datasets/body_fat_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(train_dataset_path,delimiter=',')\n",
    "test_data = np.loadtxt(test_dataset_path,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[:,:-1], train_data[:,-1:]\n",
    "X_test, y_test = test_data[:,:-1], test_data[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((train_data,test_data),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sscore(k, X):\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init='auto')\n",
    "    km.fit_predict(X)\n",
    "    return silhouette_score(X, km.labels_, metric='euclidean')\n",
    "    \n",
    "k_min,k_max = 1,12\n",
    "ss = []\n",
    "for k in range(k_min, k_max):\n",
    "    if k > 1:\n",
    "        ss.append(sscore(k, X))\n",
    "    else: \n",
    "        ss.append(1)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 4))  # Create a single plot\n",
    "\n",
    "# kx = range(k_min, k_max)\n",
    "\n",
    "# ax.set_ylim((0, 1.05))\n",
    "# ax.set_xticks(kx)\n",
    "# ax.axhline(y=0.8, color='r', linestyle='-')\n",
    "# ax.plot(kx, ss, c='green')\n",
    "# ax.scatter(kx, ss, c='green', marker='o')\n",
    "# ax.set_xlabel('X Values')\n",
    "# ax.set_ylabel('Y Values')\n",
    "# ax.set_title('Combined Line and Scatter Plot')\n",
    "# ax.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "# без виход\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0,n_init=\"auto\").fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cluster_centers(k, data,best_labels):\n",
    "\n",
    "    cluster, count = np.unique(best_labels,return_counts=True)\n",
    "    clusters_y = {i:0 for i in range(k)}\n",
    "    for index, cluster in enumerate(best_labels):\n",
    "        clusters_y[cluster] += data[index]\n",
    "    \n",
    "    for k in clusters_y.keys():\n",
    "        clusters_y[k] /= count[k] \n",
    "        \n",
    "    \n",
    "    return clusters_y\n",
    "\n",
    "        \n",
    "cluster_centers_y = calculate_cluster_centers(n_clusters, y_train.flatten(),kmeans.labels_)\n",
    "# cluster_centers = np.hstack((kmeans_train.cluster_centers_,np.array(list(cluster_centers_y.values())).reshape(-1,1)))\n",
    "new_y_train = [cluster_centers_y[label] for label in kmeans.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vector1, vector2):\n",
    "    return np.linalg.norm(vector1-vector2)\n",
    "\n",
    "def find_closest_cluster(vector, cluster_centers):\n",
    "    min_distance = float(\"inf\")\n",
    "    min_distance_index = float(\"inf\")\n",
    "    \n",
    "    for index, cluster in enumerate(cluster_centers):\n",
    "       distance = euclidean_distance(vector, cluster)\n",
    "\n",
    "       if distance < min_distance:\n",
    "           min_distance = distance\n",
    "           min_distance_index = index\n",
    "    \n",
    "    return min_distance_index\n",
    "\n",
    "test_labels = [find_closest_cluster(vector,kmeans.cluster_centers_) for vector in X_test]\n",
    "new_y_test = [cluster_centers_y[label] for label in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_train_data = np.concatenate((train_data[:,:-1],np.array(new_y_train).reshape(-1,1),train_data[:,-1][:,None]),axis=1)\n",
    "enriched_test_data = np.concatenate((test_data[:,:-1],np.array(new_y_test).reshape(-1,1),test_data[:,-1][:,None]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sum = sum([a[-1] for a in enriched_train_data]) # просумована таргет колонка(вона тут остання) 20.5, 13.3, 19.6, 24.4 ...\n",
    "N = len(enriched_train_data)\n",
    "y_target_test = np.array([a[-1] for a in enriched_test_data]) # таргет колонка тесту перетворена у вектор\n",
    "y_target_train = np.array([a[-1] for a in enriched_train_data]) # таргет колонка трейну перетворена у вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = preprocess_features(enriched_train_data, enriched_train_data)\n",
    "test_features, test_labels = preprocess_features(enriched_test_data, enriched_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(train_features)\n",
    "train_features = scaler.transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Без виходу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.006999492645263672 seconds ---\n",
      "Training erros func:\n",
      "\n",
      "MAPE: 0.08056362977666354\n",
      "RMSE: 1.913441155032006\n",
      "MAE: 1.2914140762029118\n",
      "Max error: 6.035184725081873\n",
      "Median absolute error: 0.9445928905687477\n",
      "Mean Squared error: 3.661257053770217\n",
      "R2: 0.8712879818862524\n",
      "\n",
      "Testing errors func:\n",
      "\n",
      "MAPE: 0.0867173091430487\n",
      "RMSE: 1.5639869312087828\n",
      "MAE: 1.1864605266629826\n",
      "Max error: 2.919693218260079\n",
      "Median absolute error: 1.089719028040541\n",
      "Mean Squared error: 2.446055120991866\n",
      "R2: 0.6926744691456143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = SVR(kernel=\"rbf\", gamma=\"scale\", coef0=0.0, epsilon=0.001, max_iter=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "svr.fit(train_features, train_labels)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "train_pred_z = svr.predict(train_features)\n",
    "\n",
    "pred_z = svr.predict(test_features)\n",
    "\n",
    "yn_train = find_yn(train_pred_z, y_sum, N)  # застосування методу подвоєних виходів\n",
    "yn_test = find_yn(pred_z, y_sum, N)\n",
    "\n",
    "train_errors = flat_errors(y_target_train, yn_train)\n",
    "test_errors = flat_errors(y_target_test, yn_test)\n",
    "\n",
    "print(\"Training erros func:\")\n",
    "display_errors(train_errors)\n",
    "print(\"Testing errors func:\")\n",
    "display_errors(test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# З виходом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_out = KMeans(n_clusters=n_clusters, random_state=0,n_init=\"auto\").fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_y_train_out = collect_cluster_center_target_coordinates(kmeans_out.cluster_centers_,  kmeans_out.labels_)\n",
    "\n",
    "cluster_centers_without_y = kmeans_out.cluster_centers_[:,:-1]\n",
    "test_labels_out = [find_closest_cluster(vector,cluster_centers_without_y) for vector in X_test]\n",
    "new_y_test_out = [kmeans_out.cluster_centers_[label][kmeans_out.cluster_centers_.shape[1]-1] for label in test_labels_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_train_data_out = np.concatenate((train_data[:,:-1],np.array(new_y_train_out).reshape(-1,1),train_data[:,-1][:,None]),axis=1)\n",
    "enriched_test_data_out = np.concatenate((test_data[:,:-1],np.array(new_y_test_out).reshape(-1,1),test_data[:,-1][:,None]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = np.concatenate((train_data[:,:-1],ys_train,train_data[:,-1][:,None]),axis=1)\n",
    "#test_data = np.concatenate((test_data[:,:-1],ys_test,test_data[:,-1][:,None]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_out, train_labels_out = preprocess_features(enriched_train_data_out, enriched_train_data_out) #додаємо в кінець одного вектора інший вектор(процедура аугментації)\n",
    "# train_labels це наші z_1,z_2,z_3, z_4\n",
    "# робиться те саме що і в минулому випадку, але навпаки перший вектор йде в кінець а наступні на початок\n",
    "# train_labels2 точно такі самі як і train_labels тільки з іншим знаком\n",
    "test_features_out, test_labels_out = preprocess_features(enriched_test_data_out, enriched_train_data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler()\n",
    "scaler.fit(train_features_out)\n",
    "train_features_out = scaler.transform(train_features_out)\n",
    "test_features_out = scaler.transform(test_features_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.006997585296630859 seconds ---\n",
      "Training erros func:\n",
      "\n",
      "MAPE: 0.08056362977666354\n",
      "RMSE: 1.913441155032006\n",
      "MAE: 1.2914140762029118\n",
      "Max error: 6.035184725081873\n",
      "Median absolute error: 0.9445928905687477\n",
      "Mean Squared error: 3.661257053770217\n",
      "R2: 0.8712879818862524\n",
      "\n",
      "Testing errors func:\n",
      "\n",
      "MAPE: 0.0867173091430487\n",
      "RMSE: 1.5639869312087828\n",
      "MAE: 1.1864605266629826\n",
      "Max error: 2.919693218260079\n",
      "Median absolute error: 1.089719028040541\n",
      "Mean Squared error: 2.446055120991866\n",
      "R2: 0.6926744691456143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf', gamma='scale', coef0=0.0, epsilon=0.001, max_iter=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "svr.fit(train_features_out, train_labels_out)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "train_pred_z = svr.predict(train_features_out)\n",
    "\n",
    "pred_z = svr.predict(test_features_out)\n",
    "\n",
    "yn_train_out = find_yn(train_pred_z, y_sum, N) # застосування методу подвоєних виходів\n",
    "yn_test_out = find_yn(pred_z, y_sum, N)\n",
    "\n",
    "train_errors = flat_errors(y_target_train, yn_train_out)\n",
    "test_errors = flat_errors(y_target_test, yn_test_out)\n",
    "\n",
    "\n",
    "print('Training erros func:')\n",
    "display_errors(train_errors)\n",
    "print('Testing errors func:')\n",
    "display_errors(test_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
